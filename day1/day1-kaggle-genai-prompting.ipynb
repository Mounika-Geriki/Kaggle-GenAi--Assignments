{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88037dea",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-03T13:38:15.387745Z",
     "iopub.status.busy": "2025-04-03T13:38:15.387384Z",
     "iopub.status.idle": "2025-04-03T13:38:16.394825Z",
     "shell.execute_reply": "2025-04-03T13:38:16.393994Z"
    },
    "papermill": {
     "duration": 1.021091,
     "end_time": "2025-04-03T13:38:16.396590",
     "exception": false,
     "start_time": "2025-04-03T13:38:15.375499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "926ac40d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:38:16.418455Z",
     "iopub.status.busy": "2025-04-03T13:38:16.417977Z",
     "iopub.status.idle": "2025-04-03T13:38:25.137387Z",
     "shell.execute_reply": "2025-04-03T13:38:25.136201Z"
    },
    "papermill": {
     "duration": 8.732438,
     "end_time": "2025-04-03T13:38:25.139209",
     "exception": false,
     "start_time": "2025-04-03T13:38:16.406771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip uninstall -qqy jupyterlab  # Remove unused packages from Kaggle's base image that conflict\n",
    "!pip install -U -q \"google-genai==1.7.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6cbc5b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:38:25.161036Z",
     "iopub.status.busy": "2025-04-03T13:38:25.160629Z",
     "iopub.status.idle": "2025-04-03T13:38:26.484801Z",
     "shell.execute_reply": "2025-04-03T13:38:26.483719Z"
    },
    "papermill": {
     "duration": 1.337622,
     "end_time": "2025-04-03T13:38:26.487119",
     "exception": false,
     "start_time": "2025-04-03T13:38:25.149497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "from IPython.display import HTML, Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fdb0055",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:38:26.515662Z",
     "iopub.status.busy": "2025-04-03T13:38:26.514943Z",
     "iopub.status.idle": "2025-04-03T13:38:26.806668Z",
     "shell.execute_reply": "2025-04-03T13:38:26.805577Z"
    },
    "papermill": {
     "duration": 0.305493,
     "end_time": "2025-04-03T13:38:26.809193",
     "exception": false,
     "start_time": "2025-04-03T13:38:26.503700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.api_core import retry\n",
    "\n",
    "\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "genai.models.Models.generate_content = retry.Retry(\n",
    "    predicate=is_retriable)(genai.models.Models.generate_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc16fed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:38:26.843172Z",
     "iopub.status.busy": "2025-04-03T13:38:26.842581Z",
     "iopub.status.idle": "2025-04-03T13:38:26.933375Z",
     "shell.execute_reply": "2025-04-03T13:38:26.931930Z"
    },
    "papermill": {
     "duration": 0.10798,
     "end_time": "2025-04-03T13:38:26.936306",
     "exception": false,
     "start_time": "2025-04-03T13:38:26.828326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996064ce",
   "metadata": {
    "papermill": {
     "duration": 0.011505,
     "end_time": "2025-04-03T13:38:26.963605",
     "exception": false,
     "start_time": "2025-04-03T13:38:26.952100",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "FIRST PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcef98eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:38:26.985717Z",
     "iopub.status.busy": "2025-04-03T13:38:26.985269Z",
     "iopub.status.idle": "2025-04-03T13:38:29.300784Z",
     "shell.execute_reply": "2025-04-03T13:38:29.299265Z"
    },
    "papermill": {
     "duration": 2.328672,
     "end_time": "2025-04-03T13:38:29.302687",
     "exception": false,
     "start_time": "2025-04-03T13:38:26.974015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, imagine you have a really smart dog that can learn tricks. That dog is a bit like AI!\n",
      "\n",
      "Instead of teaching a dog, we're teaching a computer. We give the computer lots and lots of information, like pictures of cats, or words in a story. Then, we tell the computer what to do with that information.\n",
      "\n",
      "For example, we can show the computer lots of pictures of cats and tell it, \"This is a cat, this is a cat, this is a cat!\" Eventually, the computer learns what a cat looks like and can point out a cat in a brand new picture!\n",
      "\n",
      "That's kind of what AI is: a computer that can learn from lots of information and do smart things like recognize cats, answer questions, or even play games!\n",
      "\n",
      "Think of it like this:\n",
      "\n",
      "*   **You teach a computer (like training a dog):** You give it information.\n",
      "*   **The computer learns (like the dog learning tricks):** It figures out patterns.\n",
      "*   **The computer does something smart (like the dog doing the trick):** It recognizes things, answers questions, or solves problems.\n",
      "\n",
      "So, AI isn't a robot that thinks for itself (not yet!), but a really smart computer that can learn and do cool things with the information it's given. It's like having a super-smart helper inside your computer!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=\"Explain AI to me like I'm a kid.\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40b4a332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:38:29.324648Z",
     "iopub.status.busy": "2025-04-03T13:38:29.324228Z",
     "iopub.status.idle": "2025-04-03T13:38:29.331009Z",
     "shell.execute_reply": "2025-04-03T13:38:29.329999Z"
    },
    "papermill": {
     "duration": 0.019291,
     "end_time": "2025-04-03T13:38:29.332593",
     "exception": false,
     "start_time": "2025-04-03T13:38:29.313302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, imagine you have a really smart dog that can learn tricks. That dog is a bit like AI!\n",
       "\n",
       "Instead of teaching a dog, we're teaching a computer. We give the computer lots and lots of information, like pictures of cats, or words in a story. Then, we tell the computer what to do with that information.\n",
       "\n",
       "For example, we can show the computer lots of pictures of cats and tell it, \"This is a cat, this is a cat, this is a cat!\" Eventually, the computer learns what a cat looks like and can point out a cat in a brand new picture!\n",
       "\n",
       "That's kind of what AI is: a computer that can learn from lots of information and do smart things like recognize cats, answer questions, or even play games!\n",
       "\n",
       "Think of it like this:\n",
       "\n",
       "*   **You teach a computer (like training a dog):** You give it information.\n",
       "*   **The computer learns (like the dog learning tricks):** It figures out patterns.\n",
       "*   **The computer does something smart (like the dog doing the trick):** It recognizes things, answers questions, or solves problems.\n",
       "\n",
       "So, AI isn't a robot that thinks for itself (not yet!), but a really smart computer that can learn and do cool things with the information it's given. It's like having a super-smart helper inside your computer!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e23e29",
   "metadata": {
    "papermill": {
     "duration": 0.010054,
     "end_time": "2025-04-03T13:38:29.353486",
     "exception": false,
     "start_time": "2025-04-03T13:38:29.343432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# START A CHAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfca1747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:38:29.375684Z",
     "iopub.status.busy": "2025-04-03T13:38:29.375289Z",
     "iopub.status.idle": "2025-04-03T13:38:30.012471Z",
     "shell.execute_reply": "2025-04-03T13:38:30.011074Z"
    },
    "papermill": {
     "duration": 0.650906,
     "end_time": "2025-04-03T13:38:30.014879",
     "exception": false,
     "start_time": "2025-04-03T13:38:29.363973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Mounika! It's nice to meet you. How can I help you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat = client.chats.create(model='gemini-2.0-flash', history=[])\n",
    "response = chat.send_message('Hello! My name is Mounika!')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8a11f82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:38:30.040771Z",
     "iopub.status.busy": "2025-04-03T13:38:30.040451Z",
     "iopub.status.idle": "2025-04-03T13:38:31.897416Z",
     "shell.execute_reply": "2025-04-03T13:38:31.895976Z"
    },
    "papermill": {
     "duration": 1.870129,
     "end_time": "2025-04-03T13:38:31.899338",
     "exception": false,
     "start_time": "2025-04-03T13:38:30.029209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's a fun and interesting fact about dinosaurs:\n",
      "\n",
      "**Did you know that birds are actually modern-day dinosaurs?**\n",
      "\n",
      "That's right! The evolutionary link between birds and dinosaurs is very strong. In fact, most scientists classify birds as belonging to the clade Dinosauria.  Here's why:\n",
      "\n",
      "*   **Shared Features:** Birds and dinosaurs share many skeletal features, especially in the hips, wrists, and wishbone (furcula).\n",
      "*   **Fossil Evidence:** Fossils like Archaeopteryx show a clear transitional form between dinosaurs and birds, possessing both dinosaur-like features (teeth, bony tail) and bird-like features (feathers, wings).\n",
      "*   **Theropod Lineage:** Birds are most closely related to a group of carnivorous dinosaurs called theropods, which includes famous dinosaurs like Velociraptor and Tyrannosaurus Rex.\n",
      "*   **Feathers:** Feathers weren't just for flight! Many non-avian dinosaurs, even some quite large ones, had feathers for insulation, display, or camouflage.\n",
      "\n",
      "So, next time you see a robin hopping around, remember you're looking at a living dinosaur!\n",
      "\n",
      "Did you find that interesting, Mounika? Would you like to know something else about dinosaurs?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message('Can you tell me something interesting about dinosaurs?')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f813e79",
   "metadata": {
    "papermill": {
     "duration": 0.010447,
     "end_time": "2025-04-03T13:38:31.921124",
     "exception": false,
     "start_time": "2025-04-03T13:38:31.910677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fee9529",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:38:31.943676Z",
     "iopub.status.busy": "2025-04-03T13:38:31.943308Z",
     "iopub.status.idle": "2025-04-03T13:38:32.307364Z",
     "shell.execute_reply": "2025-04-03T13:38:32.305987Z"
    },
    "papermill": {
     "duration": 0.377438,
     "end_time": "2025-04-03T13:38:32.309098",
     "exception": false,
     "start_time": "2025-04-03T13:38:31.931660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, Mounika! I remember your name.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message('Do you remember what my name is?')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152d36bb",
   "metadata": {
    "papermill": {
     "duration": 0.010015,
     "end_time": "2025-04-03T13:38:32.329591",
     "exception": false,
     "start_time": "2025-04-03T13:38:32.319576",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Choosing a model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18349aed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:38:32.352108Z",
     "iopub.status.busy": "2025-04-03T13:38:32.351741Z",
     "iopub.status.idle": "2025-04-03T13:38:32.425200Z",
     "shell.execute_reply": "2025-04-03T13:38:32.423992Z"
    },
    "papermill": {
     "duration": 0.087328,
     "end_time": "2025-04-03T13:38:32.427368",
     "exception": false,
     "start_time": "2025-04-03T13:38:32.340040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.5-pro-exp-03-25\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-1.5-pro-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n"
     ]
    }
   ],
   "source": [
    "for model in client.models.list():\n",
    "  print(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf9af2df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:38:32.449838Z",
     "iopub.status.busy": "2025-04-03T13:38:32.449520Z",
     "iopub.status.idle": "2025-04-03T13:38:32.515373Z",
     "shell.execute_reply": "2025-04-03T13:38:32.514020Z"
    },
    "papermill": {
     "duration": 0.079108,
     "end_time": "2025-04-03T13:38:32.517275",
     "exception": false,
     "start_time": "2025-04-03T13:38:32.438167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Gemini 2.0 Flash',\n",
      " 'display_name': 'Gemini 2.0 Flash',\n",
      " 'input_token_limit': 1048576,\n",
      " 'name': 'models/gemini-2.0-flash',\n",
      " 'output_token_limit': 8192,\n",
      " 'supported_actions': ['generateContent', 'countTokens'],\n",
      " 'tuned_model_info': {},\n",
      " 'version': '2.0'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for model in client.models.list():\n",
    "  if model.name == 'models/gemini-2.0-flash':\n",
    "    pprint(model.to_json_dict())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8090e2e3",
   "metadata": {
    "papermill": {
     "duration": 0.010249,
     "end_time": "2025-04-03T13:38:32.538264",
     "exception": false,
     "start_time": "2025-04-03T13:38:32.528015",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Explore generation parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977202f5",
   "metadata": {
    "papermill": {
     "duration": 0.01023,
     "end_time": "2025-04-03T13:38:32.559032",
     "exception": false,
     "start_time": "2025-04-03T13:38:32.548802",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. Output length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a747ec6",
   "metadata": {
    "papermill": {
     "duration": 0.010172,
     "end_time": "2025-04-03T13:38:32.579671",
     "exception": false,
     "start_time": "2025-04-03T13:38:32.569499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "100 Words Essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "259e4e48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:38:32.601967Z",
     "iopub.status.busy": "2025-04-03T13:38:32.601575Z",
     "iopub.status.idle": "2025-04-03T13:38:34.132270Z",
     "shell.execute_reply": "2025-04-03T13:38:34.131040Z"
    },
    "papermill": {
     "duration": 1.544049,
     "end_time": "2025-04-03T13:38:34.134176",
     "exception": false,
     "start_time": "2025-04-03T13:38:32.590127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## The Humble Olive: A Cornerstone of Culture and Sustenance in Modern Society\n",
      "\n",
      "The olive, a small, unassuming fruit, often overlooked amidst the abundance of modern food choices, holds a surprisingly significant place in contemporary society. More than just a salty appetizer or a source of flavorful oil, the olive represents a cultural legacy spanning millennia, a key component of a healthy diet, and an economic driver for countless communities around the globe. Its importance stretches from the ancient groves of the Mediterranean to the contemporary dinner tables of bustling metropolises, making it a vital thread in the fabric of our interconnected world.\n",
      "\n",
      "Firstly, the olive's cultural significance cannot be overstated. The olive tree, *Olea europaea*, is deeply interwoven with the history and mythology of the Mediterranean region, a symbol of peace, wisdom, and prosperity. In ancient Greece, the olive tree was sacred to Athena, the goddess of wisdom, and olive wreaths were bestowed upon victorious athletes and revered citizens. This reverence is mirrored in the\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "short_config = types.GenerateContentConfig(max_output_tokens=200)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=short_config,\n",
    "    contents='Write a 1000 word essay on the importance of olives in modern society.')\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca5cfad",
   "metadata": {
    "papermill": {
     "duration": 0.010625,
     "end_time": "2025-04-03T13:38:34.155847",
     "exception": false,
     "start_time": "2025-04-03T13:38:34.145222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b517ac9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:38:34.178601Z",
     "iopub.status.busy": "2025-04-03T13:38:34.178278Z",
     "iopub.status.idle": "2025-04-03T13:38:35.398169Z",
     "shell.execute_reply": "2025-04-03T13:38:35.396929Z"
    },
    "papermill": {
     "duration": 1.233406,
     "end_time": "2025-04-03T13:38:35.400030",
     "exception": false,
     "start_time": "2025-04-03T13:38:34.166624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From groves of sun-drenched, ancient trees,\n",
      "A humble fruit, it aims to please.\n",
      "In salads bright, a savory bite,\n",
      "An oil that glows with golden light.\n",
      "\n",
      "On pizzas spread, or tapenade,\n",
      "A flavor depth that's artfully made.\n",
      "From simple snack to cultured dish,\n",
      "The olive reigns, fulfilling wish.\n",
      "\n",
      "A symbol old, of peace and grace,\n",
      "Still relevant in time and space.\n",
      "So raise a glass, to this small friend,\n",
      "Whose worth and uses know no end.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=short_config,\n",
    "    contents='Write a short poem on the importance of olives in modern society.')\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5b8dc7",
   "metadata": {
    "papermill": {
     "duration": 0.010799,
     "end_time": "2025-04-03T13:38:35.422629",
     "exception": false,
     "start_time": "2025-04-03T13:38:35.411830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2. Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c592a8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:38:35.445472Z",
     "iopub.status.busy": "2025-04-03T13:38:35.445102Z",
     "iopub.status.idle": "2025-04-03T13:38:37.606592Z",
     "shell.execute_reply": "2025-04-03T13:38:37.605288Z"
    },
    "papermill": {
     "duration": 2.175078,
     "end_time": "2025-04-03T13:38:37.608610",
     "exception": false,
     "start_time": "2025-04-03T13:38:35.433532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure\n",
      " -------------------------\n",
      "Teal\n",
      " -------------------------\n",
      "Orange\n",
      " -------------------------\n",
      "Azure\n",
      " -------------------------\n",
      "Orange\n",
      " -------------------------\n"
     ]
    }
   ],
   "source": [
    "high_temp_config = types.GenerateContentConfig(temperature=2.0)\n",
    "\n",
    "\n",
    "for _ in range(5):\n",
    "  response = client.models.generate_content(\n",
    "      model='gemini-2.0-flash',\n",
    "      config=high_temp_config,\n",
    "      contents='Pick a random colour... (respond in a single word)')\n",
    "\n",
    "  if response.text:\n",
    "    print(response.text, '-' * 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994a353f",
   "metadata": {
    "papermill": {
     "duration": 0.015082,
     "end_time": "2025-04-03T13:38:37.636050",
     "exception": false,
     "start_time": "2025-04-03T13:38:37.620968",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "setting temp =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b3c3a5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:38:37.662677Z",
     "iopub.status.busy": "2025-04-03T13:38:37.662085Z",
     "iopub.status.idle": "2025-04-03T13:38:39.630306Z",
     "shell.execute_reply": "2025-04-03T13:38:39.628913Z"
    },
    "papermill": {
     "duration": 1.983023,
     "end_time": "2025-04-03T13:38:39.632222",
     "exception": false,
     "start_time": "2025-04-03T13:38:37.649199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure\n",
      " -------------------------\n",
      "Azure\n",
      " -------------------------\n",
      "Azure\n",
      " -------------------------\n",
      "Azure\n",
      " -------------------------\n",
      "Azure\n",
      " -------------------------\n"
     ]
    }
   ],
   "source": [
    "low_temp_config = types.GenerateContentConfig(temperature=0.0)\n",
    "\n",
    "for _ in range(5):\n",
    "  response = client.models.generate_content(\n",
    "      model='gemini-2.0-flash',\n",
    "      config=low_temp_config,\n",
    "      contents='Pick a random colour... (respond in a single word)')\n",
    "\n",
    "  if response.text:\n",
    "    print(response.text, '-' * 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8710a5",
   "metadata": {
    "papermill": {
     "duration": 0.011594,
     "end_time": "2025-04-03T13:38:39.655516",
     "exception": false,
     "start_time": "2025-04-03T13:38:39.643922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**another example - try to run the code multiple times - giving diff answers each time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40df82f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:38:39.680003Z",
     "iopub.status.busy": "2025-04-03T13:38:39.679641Z",
     "iopub.status.idle": "2025-04-03T13:38:57.069046Z",
     "shell.execute_reply": "2025-04-03T13:38:57.067997Z"
    },
    "papermill": {
     "duration": 17.403751,
     "end_time": "2025-04-03T13:38:57.071032",
     "exception": false,
     "start_time": "2025-04-03T13:38:39.667281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jasper was, by all accounts, a creature of comfort. A ginger tabby with a permanent air of disdain, his days consisted of napping in sunbeams, swatting at dust motes, and demanding tuna at precisely 5 PM. Adventure, as far as Jasper was concerned, was finding the warmest spot on the radiator.\n",
      "\n",
      "But adventure, it seemed, had other plans for Jasper.\n",
      "\n",
      "It started with a cardboard box. A large, sturdy box, discarded after a particularly enthusiastic online shopping spree by his human, Emily. Jasper, naturally, claimed it as his own. He spent hours kneading the corrugated cardboard, purring contentedly in his new kingdom.\n",
      "\n",
      "One evening, after a particularly satisfying tuna feast, Jasper, feeling bolder than usual, began scratching at the box with a newfound ferocity. He clawed and pulled, driven by a strange, unfamiliar urge. Suddenly, the bottom of the box gave way.\n",
      "\n",
      "Instead of the familiar hardwood floor, Jasper found himself looking down into… darkness. Not the comfortable, sleepy darkness of his usual napping spots, but a deep, echoing darkness that seemed to pulse with a faint, earthy smell. Curiosity, a feeling rare and unsettling to Jasper, overcame his inherent caution. He jumped.\n",
      "\n",
      "He landed with a soft thud on cool, damp earth. The box, torn but still vaguely recognizable, sat above him, a distant beacon in the gloom. Jasper shook himself, his fur slightly damp and bristling with unease.\n",
      "\n",
      "He was in a tunnel. The air was thick with the scent of roots and damp soil. A sliver of moonlight, filtering through a crack in the ground above, offered the only illumination. For a moment, Jasper considered scrambling back into his box-haven. But the lure of the unknown, the whisper of adventure, was too strong to resist.\n",
      "\n",
      "He padded forward, his tail held high, a ginger explorer in a subterranean world. The tunnel twisted and turned, descending deeper into the earth. He encountered strange, scurrying creatures – fat, blind earthworms, and beetles with iridescent shells. He cautiously avoided them, his hunting instincts momentarily suppressed by a sense of wonder.\n",
      "\n",
      "Finally, the tunnel opened into a vast, underground cavern. Water dripped from the ceiling, forming shimmering pools that reflected the faint moonlight. In the center of the cavern, a single, luminous mushroom pulsed with a soft, ethereal glow.\n",
      "\n",
      "Mesmerized, Jasper approached the mushroom. As he got closer, he noticed tiny, winged creatures flitting around it, their bodies shimmering with the same otherworldly light. They looked like miniature fairies, right out of one of Emily’s children’s books.\n",
      "\n",
      "One of the fairies landed on Jasper’s nose, its tiny feet tickling. He twitched his whiskers, unsure what to do. Then, the fairy spoke, its voice a tinkling chime.\n",
      "\n",
      "“Welcome, Jasper,” it chirped. “We have been expecting you.”\n",
      "\n",
      "Jasper, understandably, was speechless.\n",
      "\n",
      "“The mushroom,” the fairy continued, “is fading. Its magic is dwindling. Only a creature of pure heart, a creature who is loved and cherished, can restore it.”\n",
      "\n",
      "Jasper, a creature of tuna and sunbeams, felt a surge of unexpected warmth in his chest. He thought of Emily, who scratched him behind the ears and always filled his bowl with the best tuna.\n",
      "\n",
      "Without hesitation, he touched his nose to the luminous mushroom. A jolt of energy surged through him, a feeling of pure, untainted love. The mushroom pulsed brighter, and the cavern was bathed in its radiant light. The fairies danced with joy, their tiny wings creating swirling patterns in the air.\n",
      "\n",
      "The next morning, Jasper woke up in his cardboard box. Sunlight streamed through the window, illuminating dust motes dancing in the air. He stretched, yawned, and licked his paw.\n",
      "\n",
      "Had it all been a dream? He wasn’t sure. But something had changed. He felt lighter, happier. He purred with an unusual intensity.\n",
      "\n",
      "When Emily came downstairs, he greeted her with an affectionate head-butt, rubbing against her legs with uncharacteristic enthusiasm. She laughed and scooped him up, burying her face in his fur.\n",
      "\n",
      "That evening, when 5 PM rolled around, and Emily placed a bowl of tuna before him, Jasper didn’t just devour it with his usual greedy gusto. He paused, looked up at her, and purred again, a deep, rumbling sound that resonated with something more than just satisfaction. It was a purr of gratitude, a purr of love, a purr that held the echo of a magical adventure. And Jasper, the cat who thought adventure was finding the warmest spot on the radiator, knew that life, like a cardboard box, could hold unexpected wonders, waiting to be discovered.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config = types.GenerateContentConfig(\n",
    "    # These are the default values for gemini-2.0-flash.\n",
    "    temperature=1.0,\n",
    "    top_p=0.95,\n",
    ")\n",
    "\n",
    "story_prompt = \"You are a creative writer. Write a short story about a cat who goes on an adventure.\"\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=model_config,\n",
    "    contents=story_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "164b8125",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:38:57.096618Z",
     "iopub.status.busy": "2025-04-03T13:38:57.096250Z",
     "iopub.status.idle": "2025-04-03T13:39:11.010914Z",
     "shell.execute_reply": "2025-04-03T13:39:11.009785Z"
    },
    "papermill": {
     "duration": 13.929223,
     "end_time": "2025-04-03T13:39:11.012735",
     "exception": false,
     "start_time": "2025-04-03T13:38:57.083512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clementine, a calico with a perpetually surprised expression, was not built for adventure. Her days were a predictable symphony of sunbeams, strategically placed naps, and the demanding meow-demands for tuna. But one particularly blustery afternoon, the world outside her usual window called.\n",
      "\n",
      "A rogue gust of wind, bold and mischievous, flung open the kitchen window. Clementine, startled from a particularly cozy nap atop the Aga, peered out. The world beyond was a swirling canvas of browns, greens, and greys. Leaves danced a frenzied ballet, and the air hummed with a wild, untamed energy she had never experienced before.\n",
      "\n",
      "Curiosity, a feeling as foreign to her as bathing, pricked her whiskers. Before she could overthink it, she launched herself into the unknown.\n",
      "\n",
      "The first step onto the damp earth was a revelation. The cool mud squished pleasantly between her paws. Suddenly, the sterile comfort of her home felt…boring. She padded cautiously forward, nose twitching, overwhelmed by a cacophony of new smells: damp earth, decaying leaves, the faint, tantalizing scent of...mouse?\n",
      "\n",
      "Her hunting instincts, dormant for so long, flickered to life. She stalked through the undergrowth, a miniature jungle to her urbanized eyes. The wind whipped her fur, making her feel like a tiny, calico pirate sailing the high seas of the garden.\n",
      "\n",
      "She encountered a fat, grumpy robin, who chirped indignantly at her intrusion. Clementine, used to the subservient cooing of humans, puffed up her chest and hissed, a rusty sound she rarely used. The robin, unimpressed, simply hopped to a higher branch and continued his scolding.\n",
      "\n",
      "Disappointed but undeterred, Clementine pressed on. She discovered a glistening dewdrop, perfectly round and shimmering with captured light. She batted at it with a paw, sending it scattering like a tiny, liquid firework. Then, she found a fallen feather, soft and grey, and chased it with the fierce abandon of a kitten.\n",
      "\n",
      "The afternoon was a kaleidoscope of sights, smells, and sensations. She climbed a surprisingly climbable tree, feeling the rough bark scratch against her claws. She watched a busy earthworm wriggle its way back into the ground. She even, dare she admit it, considered, and then rejected, chasing a butterfly. Too much effort.\n",
      "\n",
      "As the sun began to dip below the horizon, casting long, dramatic shadows, Clementine felt a pang of…something. Not quite regret, but a wistful awareness of the impending return to her normal life.\n",
      "\n",
      "She found her way back to the window, now slightly ajar. With a mighty leap, she landed back on the familiar, linoleum-covered floor.\n",
      "\n",
      "She shook herself, dislodging stray leaves and a surprising amount of mud. She felt…different. Changed. The world outside, she realized, was a vast and exciting place, full of possibilities she had never imagined.\n",
      "\n",
      "She padded into the living room, where her human was settling in for the evening. Clementine rubbed against her leg, purring a throaty rumble, a purr that held not only affection, but a hint of wildness, a secret knowledge of the adventures that lay just beyond the open window.\n",
      "\n",
      "That night, curled up in her favorite sunbeam, Clementine dreamt not of tuna, but of rustling leaves, grumpy robins, and the endless possibilities of the world outside. The adventure had been short, but the spark it ignited in her calico heart would burn brightly for a long, long time. And who knew? Perhaps tomorrow, the wind would blow again.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config = types.GenerateContentConfig(\n",
    "    # These are the default values for gemini-2.0-flash.\n",
    "    temperature=1.0,\n",
    "    top_p=0.95,\n",
    ")\n",
    "\n",
    "story_prompt = \"You are a creative writer. Write a short story about a cat who goes on an adventure.\"\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=model_config,\n",
    "    contents=story_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec7a0864",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:39:11.038494Z",
     "iopub.status.busy": "2025-04-03T13:39:11.038132Z",
     "iopub.status.idle": "2025-04-03T13:39:15.872556Z",
     "shell.execute_reply": "2025-04-03T13:39:15.871264Z"
    },
    "papermill": {
     "duration": 4.849292,
     "end_time": "2025-04-03T13:39:15.874746",
     "exception": false,
     "start_time": "2025-04-03T13:39:11.025454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clementine, a calico cat of discerning tastes and a penchant for naps in sunbeams, considered herself a creature of routine. Breakfast precisely at dawn, a rigorous grooming session, then the prime napping spot on the floral armchair. Adventure, in her mind, was limited to strategically batting dust bunnies under the sofa. Until the day the robin arrived.\n",
      "\n",
      "The robin, a brazen redhead named Rusty, perched on the windowsill, his tiny black eyes sparkling with mischief. \"Heard you've never left the garden, Clementine,\" he chirped, his voice a musical taunt.\n",
      "\n",
      "Clementine twitched her ear. \"The garden provides everything a cat needs,\" she retorted, though a flicker of curiosity sparked within her.\n",
      "\n",
      "\"Everything?\" Rusty hopped closer. \"You've never seen the Whispering Woods, or tasted the wild berries that grow beyond the fence! Imagine, Clementine, a whole world of smells, tastes, and... well, bigger dust bunnies!\"\n",
      "\n",
      "The last part was what truly piqued her interest. Clementine stretched, her claws digging into the armchair. \"And what, pray tell, is beyond the fence?\"\n",
      "\n",
      "Rusty launched himself into the air. \"Adventure, my dear! Adventure!\" He beckoned with a flick of his wing towards the looming wooden fence.\n",
      "\n",
      "Clementine, against her better judgment, felt a thrill. She had never dared to even *think* about venturing beyond the garden, the safe haven she knew so well. But Rusty's words, the image of colossal dust bunnies, and a sudden, overwhelming desire to prove Rusty wrong, fueled her.\n",
      "\n",
      "She slipped through a gap under the fence, the scent of damp earth and unfamiliar foliage assaulting her senses. The Whispering Woods lived up to its name, rustling with secrets in the breeze. Towering trees cast long shadows, and the air hummed with the buzz of unseen insects.\n",
      "\n",
      "Rusty led the way, flitting through the branches, a tiny, feathered tour guide. Clementine, accustomed to the smooth lawn of her garden, found the uneven ground challenging. She tripped over roots, dodged prickly bushes, and even had a brief, terrifying encounter with a particularly large snail.\n",
      "\n",
      "Finally, they arrived at a clearing. There, bathed in sunlight, grew bushes laden with plump, juicy berries. They were unlike anything Clementine had ever tasted - sweet and tart, bursting with flavor. She feasted, her fur stained crimson, forgetting all about dust bunnies and danger.\n",
      "\n",
      "As dusk began to settle, a pang of homesickness tugged at her. The familiar scent of her garden, the thought of her warm, cozy bed, filled her with longing.\n",
      "\n",
      "Rusty, perched on a branch, seemed to sense her change of heart. \"Ready to go back, Clementine?\" he asked, his voice surprisingly gentle.\n",
      "\n",
      "Clementine nodded. The adventure had been exhilarating, but she was ready for the comfort of the familiar.\n",
      "\n",
      "The return journey was quicker. When she finally slipped back under the fence, the garden felt like a haven. She collapsed onto her floral armchair, the scent of lavender and sunshine washing over her.\n",
      "\n",
      "That night, Clementine dreamt of whispering woods, sweet berries, and a cheeky robin. The adventure had changed her. She was still a cat of discerning tastes and a penchant for naps, but now, she was also a cat who knew that adventure, however messy and unexpected, could be found just beyond the fence. And sometimes, the best adventures are the ones that lead you back home.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config = types.GenerateContentConfig(\n",
    "    # These are the default values for gemini-2.0-flash.\n",
    "    temperature=1.0,\n",
    "    top_p=0.95,\n",
    ")\n",
    "\n",
    "story_prompt = \"You are a creative writer. Write a short story about a cat who goes on an adventure.\"\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=model_config,\n",
    "    contents=story_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5dcfd4",
   "metadata": {
    "papermill": {
     "duration": 0.011326,
     "end_time": "2025-04-03T13:39:15.899795",
     "exception": false,
     "start_time": "2025-04-03T13:39:15.888469",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d08954",
   "metadata": {
    "papermill": {
     "duration": 0.011579,
     "end_time": "2025-04-03T13:39:15.923062",
     "exception": false,
     "start_time": "2025-04-03T13:39:15.911483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. Zero Shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06f0fb74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:39:15.948701Z",
     "iopub.status.busy": "2025-04-03T13:39:15.948319Z",
     "iopub.status.idle": "2025-04-03T13:39:16.268402Z",
     "shell.execute_reply": "2025-04-03T13:39:16.267232Z"
    },
    "papermill": {
     "duration": 0.335305,
     "end_time": "2025-04-03T13:39:16.270145",
     "exception": false,
     "start_time": "2025-04-03T13:39:15.934840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config = types.GenerateContentConfig(\n",
    "    temperature=0.1,\n",
    "    top_p=1,\n",
    "    max_output_tokens=5,\n",
    ")\n",
    "\n",
    "zero_shot_prompt = \"\"\"Classify movie reviews as POSITIVE, NEUTRAL or NEGATIVE.\n",
    "Review: \"Her\" is a disturbing study revealing the direction\n",
    "humanity is headed if AI is allowed to keep evolving,\n",
    "unchecked. I wish there were more movies like this masterpiece.\n",
    "Sentiment: \"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=model_config,\n",
    "    contents=zero_shot_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5dd1bd",
   "metadata": {
    "papermill": {
     "duration": 0.011889,
     "end_time": "2025-04-03T13:39:16.294374",
     "exception": false,
     "start_time": "2025-04-03T13:39:16.282485",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1.1 Enum mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43917b77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:39:16.319073Z",
     "iopub.status.busy": "2025-04-03T13:39:16.318699Z",
     "iopub.status.idle": "2025-04-03T13:39:16.735745Z",
     "shell.execute_reply": "2025-04-03T13:39:16.734315Z"
    },
    "papermill": {
     "duration": 0.431393,
     "end_time": "2025-04-03T13:39:16.737584",
     "exception": false,
     "start_time": "2025-04-03T13:39:16.306191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "import enum\n",
    "\n",
    "class Sentiment(enum.Enum):\n",
    "    POSITIVE = \"positive\"\n",
    "    NEUTRAL = \"neutral\"\n",
    "    NEGATIVE = \"negative\"\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=types.GenerateContentConfig(\n",
    "        response_mime_type=\"text/x.enum\",\n",
    "        response_schema=Sentiment\n",
    "    ),\n",
    "    contents=zero_shot_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cf7e9e",
   "metadata": {
    "papermill": {
     "duration": 0.070957,
     "end_time": "2025-04-03T13:39:16.821649",
     "exception": false,
     "start_time": "2025-04-03T13:39:16.750692",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When using constrained output like an enum, the Python SDK will attempt to convert the model's text response into a Python object automatically. It's stored in the response.parsed field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8f044eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:39:16.846994Z",
     "iopub.status.busy": "2025-04-03T13:39:16.846598Z",
     "iopub.status.idle": "2025-04-03T13:39:16.851834Z",
     "shell.execute_reply": "2025-04-03T13:39:16.850718Z"
    },
    "papermill": {
     "duration": 0.019706,
     "end_time": "2025-04-03T13:39:16.853501",
     "exception": false,
     "start_time": "2025-04-03T13:39:16.833795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment.POSITIVE\n",
      "<enum 'Sentiment'>\n"
     ]
    }
   ],
   "source": [
    "enum_response = response.parsed\n",
    "print(enum_response)\n",
    "print(type(enum_response))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987b4988",
   "metadata": {
    "papermill": {
     "duration": 0.0118,
     "end_time": "2025-04-03T13:39:16.877469",
     "exception": false,
     "start_time": "2025-04-03T13:39:16.865669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2. One-shot and few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a1c9c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:39:16.903484Z",
     "iopub.status.busy": "2025-04-03T13:39:16.903042Z",
     "iopub.status.idle": "2025-04-03T13:39:17.346628Z",
     "shell.execute_reply": "2025-04-03T13:39:17.345478Z"
    },
    "papermill": {
     "duration": 0.458833,
     "end_time": "2025-04-03T13:39:17.348285",
     "exception": false,
     "start_time": "2025-04-03T13:39:16.889452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\"size\": \"large\",\n",
      "\"type\": \"normal\",\n",
      "\"ingredients\": [\"cheese\", \"pineapple\"]\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "few_shot_prompt = \"\"\"Parse a customer's pizza order into valid JSON:\n",
    "\n",
    "EXAMPLE:\n",
    "I want a small pizza with cheese, tomato sauce, and pepperoni.\n",
    "JSON Response:\n",
    "```\n",
    "{\n",
    "\"size\": \"small\",\n",
    "\"type\": \"normal\",\n",
    "\"ingredients\": [\"cheese\", \"tomato sauce\", \"pepperoni\"]\n",
    "}\n",
    "```\n",
    "\n",
    "EXAMPLE:\n",
    "Can I get a large pizza with tomato sauce, basil and mozzarella\n",
    "JSON Response:\n",
    "```\n",
    "{\n",
    "\"size\": \"large\",\n",
    "\"type\": \"normal\",\n",
    "\"ingredients\": [\"tomato sauce\", \"basil\", \"mozzarella\"]\n",
    "}\n",
    "```\n",
    "\n",
    "ORDER:\n",
    "\"\"\"\n",
    "\n",
    "customer_order = \"Give me a large with cheese & pineapple\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0.1,\n",
    "        top_p=1,\n",
    "        max_output_tokens=250,\n",
    "    ),\n",
    "    contents=[few_shot_prompt, customer_order])\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03861350",
   "metadata": {
    "papermill": {
     "duration": 0.011642,
     "end_time": "2025-04-03T13:39:17.372091",
     "exception": false,
     "start_time": "2025-04-03T13:39:17.360449",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2.2 Json mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51f76ded",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:39:17.397066Z",
     "iopub.status.busy": "2025-04-03T13:39:17.396679Z",
     "iopub.status.idle": "2025-04-03T13:39:17.922515Z",
     "shell.execute_reply": "2025-04-03T13:39:17.920830Z"
    },
    "papermill": {
     "duration": 0.54041,
     "end_time": "2025-04-03T13:39:17.924373",
     "exception": false,
     "start_time": "2025-04-03T13:39:17.383963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"size\": \"large\",\n",
      "  \"ingredients\": [\"apple\", \"chocolate\"],\n",
      "  \"type\": \"dessert\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import typing_extensions as typing\n",
    "\n",
    "class PizzaOrder(typing.TypedDict):\n",
    "    size: str\n",
    "    ingredients: list[str]\n",
    "    type: str\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0.1,\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=PizzaOrder,\n",
    "    ),\n",
    "    contents=\"Can I have a large dessert pizza with apple and chocolate\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c01bec",
   "metadata": {
    "papermill": {
     "duration": 0.011581,
     "end_time": "2025-04-03T13:39:17.948630",
     "exception": false,
     "start_time": "2025-04-03T13:39:17.937049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "3. Chain of Thought (CoT) prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "631100e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:39:17.973579Z",
     "iopub.status.busy": "2025-04-03T13:39:17.973227Z",
     "iopub.status.idle": "2025-04-03T13:39:18.295448Z",
     "shell.execute_reply": "2025-04-03T13:39:18.294291Z"
    },
    "papermill": {
     "duration": 0.33662,
     "end_time": "2025-04-03T13:39:18.297099",
     "exception": false,
     "start_time": "2025-04-03T13:39:17.960479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"When I was 4 years old, my partner was 3 times my age. Now, I\n",
    "am 20 years old. How old is my partner? Return the answer directly.\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    contents=prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97a74d0",
   "metadata": {
    "papermill": {
     "duration": 0.011868,
     "end_time": "2025-04-03T13:39:18.321433",
     "exception": false,
     "start_time": "2025-04-03T13:39:18.309565",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Think Step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a23e64bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:39:18.346601Z",
     "iopub.status.busy": "2025-04-03T13:39:18.346283Z",
     "iopub.status.idle": "2025-04-03T13:39:19.363272Z",
     "shell.execute_reply": "2025-04-03T13:39:19.362158Z"
    },
    "papermill": {
     "duration": 1.03167,
     "end_time": "2025-04-03T13:39:19.365111",
     "exception": false,
     "start_time": "2025-04-03T13:39:18.333441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's how to solve this problem step-by-step:\n",
       "\n",
       "1.  **Find the age difference:** When you were 4, your partner was 3 times your age, meaning they were 4 * 3 = 12 years old.\n",
       "2.  **Calculate the age difference:** The age difference between you and your partner is 12 - 4 = 8 years.\n",
       "3.  **Determine the partner's current age:** Since the age difference remains constant, your partner is always 8 years older than you. If you are now 20, your partner is 20 + 8 = 28 years old.\n",
       "\n",
       "**Therefore, your partner is currently 28 years old.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"When I was 4 years old, my partner was 3 times my age. Now,\n",
    "I am 20 years old. How old is my partner? Let's think step by step.\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    contents=prompt)\n",
    "\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35c0644",
   "metadata": {
    "papermill": {
     "duration": 0.011805,
     "end_time": "2025-04-03T13:39:19.389632",
     "exception": false,
     "start_time": "2025-04-03T13:39:19.377827",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "4. **ReAct: Reason and act**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2ec9642",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:39:19.414946Z",
     "iopub.status.busy": "2025-04-03T13:39:19.414570Z",
     "iopub.status.idle": "2025-04-03T13:39:19.419809Z",
     "shell.execute_reply": "2025-04-03T13:39:19.418770Z"
    },
    "papermill": {
     "duration": 0.019692,
     "end_time": "2025-04-03T13:39:19.421306",
     "exception": false,
     "start_time": "2025-04-03T13:39:19.401614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_instructions = \"\"\"\n",
    "Solve a question answering task with interleaving Thought, Action, Observation steps. Thought can reason about the current situation,\n",
    "Observation is understanding relevant information from an Action's output and Action can be one of three types:\n",
    " (1) <search>entity</search>, which searches the exact entity on Wikipedia and returns the first paragraph if it exists. If not, it\n",
    "     will return some similar entities to search and you can try to search the information from those topics.\n",
    " (2) <lookup>keyword</lookup>, which returns the next sentence containing keyword in the current context. This only does exact matches,\n",
    "     so keep your searches short.\n",
    " (3) <finish>answer</finish>, which returns the answer and finishes the task.\n",
    "\"\"\"\n",
    "\n",
    "example1 = \"\"\"Question\n",
    "Musician and satirist Allie Goertz wrote a song about the \"The Simpsons\" character Milhouse, who Matt Groening named after who?\n",
    "\n",
    "Thought 1\n",
    "The question simplifies to \"The Simpsons\" character Milhouse is named after who. I only need to search Milhouse and find who it is named after.\n",
    "\n",
    "Action 1\n",
    "<search>Milhouse</search>\n",
    "Observation 1\n",
    "Milhouse Mussolini Van Houten is a recurring character in the Fox animated television series The Simpsons voiced by Pamela Hayden and created by Matt Groening.\n",
    "\n",
    "Thought 2\n",
    "The paragraph does not tell who Milhouse is named after, maybe I can look up \"named after\".\n",
    "\n",
    "Action 2\n",
    "<lookup>named after</lookup>\n",
    "\n",
    "Observation 2\n",
    "Milhouse was named after U.S. president Richard Nixon, whose middle name was Milhous.\n",
    "\n",
    "Thought 3\n",
    "Milhouse was named after U.S. president Richard Nixon, so the answer is Richard Nixon.\n",
    "\n",
    "Action 3\n",
    "<finish>Richard Nixon</finish>\n",
    "\"\"\"\n",
    "example2 = \"\"\"Question\n",
    "What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?\n",
    "\n",
    "Thought 1\n",
    "I need to search Colorado orogeny, find the area that the eastern sector of the Colorado orogeny extends into, then find the elevation range of the area.\n",
    "\n",
    "Action 1\n",
    "<search>Colorado orogeny</search>\n",
    "\n",
    "Observation 1\n",
    "The Colorado orogeny was an episode of mountain building (an orogeny) in Colorado and surrounding areas.\n",
    "\n",
    "Thought 2\n",
    "It does not mention the eastern sector. So I need to look up eastern sector.\n",
    "\n",
    "Action 2\n",
    "<lookup>eastern sector</lookup>\n",
    "\n",
    "Observation 2\n",
    "The eastern sector extends into the High Plains and is called the Central Plains orogeny.\n",
    "\n",
    "Thought 3\n",
    "The eastern sector of Colorado orogeny extends into the High Plains. So I need to search High Plains and find its elevation range.\n",
    "\n",
    "Action 3\n",
    "<search>High Plains</search>\n",
    "\n",
    "Observation 3\n",
    "High Plains refers to one of two distinct land regions\n",
    "\n",
    "Thought 4\n",
    "I need to instead search High Plains (United States).\n",
    "\n",
    "Action 4\n",
    "<search>High Plains (United States)</search>\n",
    "\n",
    "Observation 4\n",
    "The High Plains are a subregion of the Great Plains. From east to west, the High Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130m).\n",
    "\n",
    "Thought 5\n",
    "High Plains rise in elevation from around 1,800 to 7,000 ft, so the answer is 1,800 to 7,000 ft.\n",
    "\n",
    "Action 5\n",
    "<finish>1,800 to 7,000 ft</finish>\n",
    "\"\"\"\n",
    "\n",
    "# Come up with more examples yourself, or take a look through https://github.com/ysymyth/ReAct/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a56ddec",
   "metadata": {
    "papermill": {
     "duration": 0.011808,
     "end_time": "2025-04-03T13:39:19.445420",
     "exception": false,
     "start_time": "2025-04-03T13:39:19.433612",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "to ignore halucinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd98dd7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:39:19.471009Z",
     "iopub.status.busy": "2025-04-03T13:39:19.470611Z",
     "iopub.status.idle": "2025-04-03T13:39:19.965511Z",
     "shell.execute_reply": "2025-04-03T13:39:19.964399Z"
    },
    "papermill": {
     "duration": 0.509538,
     "end_time": "2025-04-03T13:39:19.967085",
     "exception": false,
     "start_time": "2025-04-03T13:39:19.457547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought 1\n",
      "I need to find the transformers NLP paper, find the authors, and then find the youngest author.\n",
      "\n",
      "Action 1\n",
      "<search>transformers NLP paper</search>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"Question\n",
    "Who was the youngest author listed on the transformers NLP paper?\n",
    "\"\"\"\n",
    "\n",
    "# You will perform the Action; so generate up to, but not including, the Observation.\n",
    "react_config = types.GenerateContentConfig(\n",
    "    stop_sequences=[\"\\nObservation\"],\n",
    "    system_instruction=model_instructions + example1 + example2,\n",
    ")\n",
    "\n",
    "# Create a chat that has the model instructions and examples pre-seeded.\n",
    "react_chat = client.chats.create(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=react_config,\n",
    ")\n",
    "\n",
    "resp = react_chat.send_message(question)\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11081172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:39:19.993189Z",
     "iopub.status.busy": "2025-04-03T13:39:19.992787Z",
     "iopub.status.idle": "2025-04-03T13:39:20.822058Z",
     "shell.execute_reply": "2025-04-03T13:39:20.820698Z"
    },
    "papermill": {
     "duration": 0.843929,
     "end_time": "2025-04-03T13:39:20.823651",
     "exception": false,
     "start_time": "2025-04-03T13:39:19.979722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought 2\n",
      "The authors are Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin. I need to find their ages and then find the youngest one. I will start by searching for Ashish Vaswani.\n",
      "\n",
      "Action 2\n",
      "<search>Ashish Vaswani</search>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "observation = \"\"\"Observation 1\n",
    "[1706.03762] Attention Is All You Need\n",
    "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\n",
    "We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.\n",
    "\"\"\"\n",
    "resp = react_chat.send_message(observation)\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808251ca",
   "metadata": {
    "papermill": {
     "duration": 0.012316,
     "end_time": "2025-04-03T13:39:20.848919",
     "exception": false,
     "start_time": "2025-04-03T13:39:20.836603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This process repeats until the <finish> action is reached. You can continue running this yourself if you like, or try the Wikipedia example to see a fully automated ReAct system at work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe19aeb",
   "metadata": {
    "papermill": {
     "duration": 0.012605,
     "end_time": "2025-04-03T13:39:20.874462",
     "exception": false,
     "start_time": "2025-04-03T13:39:20.861857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Thinking mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9bcf1aef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:39:20.901338Z",
     "iopub.status.busy": "2025-04-03T13:39:20.900956Z",
     "iopub.status.idle": "2025-04-03T13:39:36.405261Z",
     "shell.execute_reply": "2025-04-03T13:39:36.404252Z"
    },
    "papermill": {
     "duration": 15.519221,
     "end_time": "2025-04-03T13:39:36.406948",
     "exception": false,
     "start_time": "2025-04-03T13:39:20.887727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on publicly available information, **Aidan N. Gomez** is likely the youngest author listed on the \"Attention is All You Need\" paper (the Transformer paper).\n",
       "\n",
       "Here's why:\n",
       "\n",
       "* **Aidan N. Gomez** was a PhD student at the University of Toronto at the time of the paper's publication. PhD students are generally earlier in their careers and younger than established researchers at companies like Google.\n",
       "* The other authors were primarily affiliated with Google Brain and are generally more established researchers in the field.\n",
       "\n",
       "While we don't have exact birthdates for all authors to definitively say who is *absolutely* the youngest,  being a PhD student at the time of publication strongly suggests Aidan N. Gomez was the youngest author among the group.\n",
       "\n",
       "It's important to note that \"youngest\" is relative and based on typical career trajectories.  Without access to private information like birthdates, this is the most reasonable conclusion based on publicly available professional information."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "from IPython.display import Markdown, clear_output\n",
    "\n",
    "\n",
    "response = client.models.generate_content_stream(\n",
    "    model='gemini-2.0-flash-thinking-exp',\n",
    "    contents='Who was the youngest author listed on the transformers NLP paper?',\n",
    ")\n",
    "\n",
    "buf = io.StringIO()\n",
    "for chunk in response:\n",
    "    buf.write(chunk.text)\n",
    "    # Display the response as it is streamed\n",
    "    print(chunk.text, end='')\n",
    "\n",
    "# And then render the finished response as formatted markdown.\n",
    "clear_output()\n",
    "Markdown(buf.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5280af58",
   "metadata": {
    "papermill": {
     "duration": 0.012431,
     "end_time": "2025-04-03T13:39:36.432209",
     "exception": false,
     "start_time": "2025-04-03T13:39:36.419778",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Code prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab353d9e",
   "metadata": {
    "papermill": {
     "duration": 0.012228,
     "end_time": "2025-04-03T13:39:36.457090",
     "exception": false,
     "start_time": "2025-04-03T13:39:36.444862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generating code\n",
    "\n",
    "The Gemini family of models can be used to generate code, configuration and scripts. Generating code can be helpful when learning to code, learning a new language or for rapidly generating a first draft.\n",
    "\n",
    "It's important to be aware that since LLMs can make mistakes, and can repeat training data, it's essential to read and test your code first, and comply with any relevant licenses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7f3ee77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:39:36.483500Z",
     "iopub.status.busy": "2025-04-03T13:39:36.483168Z",
     "iopub.status.idle": "2025-04-03T13:39:37.019645Z",
     "shell.execute_reply": "2025-04-03T13:39:37.018618Z"
    },
    "papermill": {
     "duration": 0.551806,
     "end_time": "2025-04-03T13:39:37.021336",
     "exception": false,
     "start_time": "2025-04-03T13:39:36.469530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def factorial(n):\n",
       "  if n == 0:\n",
       "    return 1\n",
       "  else:\n",
       "    return n * factorial(n-1)\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Gemini models love to talk, so it helps to specify they stick to the code if that\n",
    "# is all that you want.\n",
    "code_prompt = \"\"\"\n",
    "Write a Python function to calculate the factorial of a number. No explanation, provide only the code.\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=1,\n",
    "        top_p=1,\n",
    "        max_output_tokens=1024,\n",
    "    ),\n",
    "    contents=code_prompt)\n",
    "\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de332bb4",
   "metadata": {
    "papermill": {
     "duration": 0.012355,
     "end_time": "2025-04-03T13:39:37.046643",
     "exception": false,
     "start_time": "2025-04-03T13:39:37.034288",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Code execution\n",
    "The Gemini API can automatically run generated code too, and will return the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c8ced81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:39:37.073202Z",
     "iopub.status.busy": "2025-04-03T13:39:37.072801Z",
     "iopub.status.idle": "2025-04-03T13:39:39.199914Z",
     "shell.execute_reply": "2025-04-03T13:39:39.198625Z"
    },
    "papermill": {
     "duration": 2.142576,
     "end_time": "2025-04-03T13:39:39.201820",
     "exception": false,
     "start_time": "2025-04-03T13:39:37.059244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code_execution_result': None,\n",
      " 'executable_code': None,\n",
      " 'file_data': None,\n",
      " 'function_call': None,\n",
      " 'function_response': None,\n",
      " 'inline_data': None,\n",
      " 'text': 'Okay, I can do that. First, I need to generate the first 14 odd '\n",
      "         'prime numbers. Remember that a prime number is a number greater than '\n",
      "         '1 that has only two factors: 1 and itself. Odd prime numbers exclude '\n",
      "         'the number 2.\\n'\n",
      "         '\\n'\n",
      "         \"Here's how I will find them: I'll start listing odd numbers and \"\n",
      "         'check if they are prime.\\n'\n",
      "         '\\n',\n",
      " 'thought': None,\n",
      " 'video_metadata': None}\n",
      "-----\n",
      "{'code_execution_result': None,\n",
      " 'executable_code': ExecutableCode(code='def is_prime(n):\\n    \"\"\"Check if a number is prime.\"\"\"\\n    if n <= 1:\\n        return False\\n    for i in range(2, int(n**0.5) + 1):\\n        if n % i == 0:\\n            return False\\n    return True\\n\\nodd_primes = []\\nnum = 3\\nwhile len(odd_primes) < 14:\\n    if is_prime(num):\\n        odd_primes.append(num)\\n    num += 2\\n\\nprint(f\\'{odd_primes=}\\')\\n\\nimport numpy as np\\nsum_of_primes = np.sum(odd_primes)\\nprint(f\\'{sum_of_primes=}\\')\\n\\n', language=<Language.PYTHON: 'PYTHON'>),\n",
      " 'file_data': None,\n",
      " 'function_call': None,\n",
      " 'function_response': None,\n",
      " 'inline_data': None,\n",
      " 'text': None,\n",
      " 'thought': None,\n",
      " 'video_metadata': None}\n",
      "-----\n",
      "{'code_execution_result': CodeExecutionResult(outcome=<Outcome.OUTCOME_OK: 'OUTCOME_OK'>, output='odd_primes=[3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47]\\nsum_of_primes=np.int64(326)\\n'),\n",
      " 'executable_code': None,\n",
      " 'file_data': None,\n",
      " 'function_call': None,\n",
      " 'function_response': None,\n",
      " 'inline_data': None,\n",
      " 'text': None,\n",
      " 'thought': None,\n",
      " 'video_metadata': None}\n",
      "-----\n",
      "{'code_execution_result': None,\n",
      " 'executable_code': None,\n",
      " 'file_data': None,\n",
      " 'function_call': None,\n",
      " 'function_response': None,\n",
      " 'inline_data': None,\n",
      " 'text': 'The first 14 odd prime numbers are 3, 5, 7, 11, 13, 17, 19, 23, 29, '\n",
      "         '31, 37, 41, 43, and 47. Their sum is 326.\\n',\n",
      " 'thought': None,\n",
      " 'video_metadata': None}\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "config = types.GenerateContentConfig(\n",
    "    tools=[types.Tool(code_execution=types.ToolCodeExecution())],\n",
    ")\n",
    "\n",
    "code_exec_prompt = \"\"\"\n",
    "Generate the first 14 odd prime numbers, then calculate their sum.\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=config,\n",
    "    contents=code_exec_prompt)\n",
    "\n",
    "for part in response.candidates[0].content.parts:\n",
    "    pprint(part.__dict__)#pprint(vars(part))\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329a61f4",
   "metadata": {
    "papermill": {
     "duration": 0.012537,
     "end_time": "2025-04-03T13:39:39.227984",
     "exception": false,
     "start_time": "2025-04-03T13:39:39.215447",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**couldnt get in json format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a945a991",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:39:39.255046Z",
     "iopub.status.busy": "2025-04-03T13:39:39.254683Z",
     "iopub.status.idle": "2025-04-03T13:39:39.265925Z",
     "shell.execute_reply": "2025-04-03T13:39:39.264831Z"
    },
    "papermill": {
     "duration": 0.027084,
     "end_time": "2025-04-03T13:39:39.267925",
     "exception": false,
     "start_time": "2025-04-03T13:39:39.240841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, I can do that. First, I need to generate the first 14 odd prime numbers. Remember that a prime number is a number greater than 1 that has only two factors: 1 and itself. Odd prime numbers exclude the number 2.\n",
       "\n",
       "Here's how I will find them: I'll start listing odd numbers and check if they are prime.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def is_prime(n):\n",
       "    \"\"\"Check if a number is prime.\"\"\"\n",
       "    if n <= 1:\n",
       "        return False\n",
       "    for i in range(2, int(n**0.5) + 1):\n",
       "        if n % i == 0:\n",
       "            return False\n",
       "    return True\n",
       "\n",
       "odd_primes = []\n",
       "num = 3\n",
       "while len(odd_primes) < 14:\n",
       "    if is_prime(num):\n",
       "        odd_primes.append(num)\n",
       "    num += 2\n",
       "\n",
       "print(f'{odd_primes=}')\n",
       "\n",
       "import numpy as np\n",
       "sum_of_primes = np.sum(odd_primes)\n",
       "print(f'{sum_of_primes=}')\n",
       "\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "odd_primes=[3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47]\n",
       "sum_of_primes=np.int64(326)\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The first 14 odd prime numbers are 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, and 47. Their sum is 326.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for part in response.candidates[0].content.parts:\n",
    "    if part.text:\n",
    "        display(Markdown(part.text))\n",
    "    elif part.executable_code:\n",
    "        display(Markdown(f'```python\\n{part.executable_code.code}\\n```'))\n",
    "    elif part.code_execution_result:\n",
    "        if part.code_execution_result.outcome != 'OUTCOME_OK':\n",
    "            display(Markdown(f'## Status {part.code_execution_result.outcome}'))\n",
    "\n",
    "        display(Markdown(f'```\\n{part.code_execution_result.output}\\n```'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1030d2",
   "metadata": {
    "papermill": {
     "duration": 0.013041,
     "end_time": "2025-04-03T13:39:39.295747",
     "exception": false,
     "start_time": "2025-04-03T13:39:39.282706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Explaining code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f818d8a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T13:39:39.324933Z",
     "iopub.status.busy": "2025-04-03T13:39:39.324588Z",
     "iopub.status.idle": "2025-04-03T13:39:41.992690Z",
     "shell.execute_reply": "2025-04-03T13:39:41.991455Z"
    },
    "papermill": {
     "duration": 2.685322,
     "end_time": "2025-04-03T13:39:41.994509",
     "exception": false,
     "start_time": "2025-04-03T13:39:39.309187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This file is a Bash script designed to enhance your command-line prompt with Git repository information.\n",
       "\n",
       "**In essence, it does the following:**\n",
       "\n",
       "*   **Displays Git Status:** Shows the current branch, whether there are uncommitted changes (staged, unstaged, untracked), and the status of your branch relative to the remote (ahead, behind).\n",
       "*   **Customizable Appearance:** It allows you to customize the colors and symbols used in the prompt to match your preferences.  It uses themes to manage the look and feel.\n",
       "*   **Asynchronous Updates:** The script can fetch the status of remote branches in the background, so the prompt doesn't slow down your workflow.\n",
       "*   **Virtual Environment Support:**  It can also display the name of the active Python virtual environment in your prompt.\n",
       "\n",
       "**Why would you use it?**\n",
       "\n",
       "*   **Git Awareness:** To be constantly aware of the state of your Git repository without having to type `git status` all the time.\n",
       "*   **Improved Workflow:** Quickly see if you have changes to commit, if you're on the correct branch, and if you're up-to-date with the remote.\n",
       "*   **Personalization:** To make your command-line environment more informative and visually appealing.\n",
       "*   **Increased Productivity:** Helps you manage your Git repositories more efficiently.\n",
       "\n",
       "To use it, you would typically source this script in your `.bashrc` or `.zshrc` file. This means adding a line like `source /path/to/this/script.sh` to your shell configuration file.  After restarting your terminal or sourcing the configuration file, your prompt will be updated with Git information.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_contents = !curl https://raw.githubusercontent.com/magicmonty/bash-git-prompt/refs/heads/master/gitprompt.sh\n",
    "\n",
    "explain_prompt = f\"\"\"\n",
    "Please explain what this file does at a very high level. What is it, and why would I use it?\n",
    "\n",
    "```\n",
    "{file_contents}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    contents=explain_prompt)\n",
    "\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed4b9e9",
   "metadata": {
    "papermill": {
     "duration": 0.012956,
     "end_time": "2025-04-03T13:39:42.022449",
     "exception": false,
     "start_time": "2025-04-03T13:39:42.009493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 90.272492,
   "end_time": "2025-04-03T13:39:42.856314",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-03T13:38:12.583822",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
